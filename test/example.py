"""
Runner ç±»ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„ Runner æ¥è‡ªå®šä¹‰ LLMSession çš„è¾“å‡ºå¤„ç†
"""
from typing import List, Dict, Any, Optional, Literal, Union

from hq_agent_sdk import (
    LLMSession, AgentConfig, OpenAIClient, OllamaClient,
    DefaultRunner
)


def get_weather(city: str) -> str:
    """
    è·å–åŸå¸‚å¤©æ°”ä¿¡æ¯
    
    :param city: åŸå¸‚åç§°
    """
    weather_data = {
        "åŒ—äº¬": "æ™´å¤©ï¼Œ20Â°C",
        "ä¸Šæµ·": "å¤šäº‘ï¼Œ18Â°C", 
        "å¹¿å·": "å°é›¨ï¼Œ25Â°C"
    }
    return weather_data.get(city, f"{city}çš„å¤©æ°”ä¿¡æ¯æš‚ä¸å¯ç”¨")


def calculate(expression: str) -> float:
    """
    è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
    
    :param expression: æ•°å­¦è¡¨è¾¾å¼å­—ç¬¦ä¸²
    """
    try:
        result = eval(expression)
        return result
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


# Hookå‡½æ•°ï¼Œç”¨äºè½»é‡åŒ–çš„LLMSession before/afterå‡½æ•°åˆ—è¡¨
def tools_before_hook(tool_name: str, args: Dict[str, Any], session) -> Dict[str, Any]:
    """
    æ˜¾ç¤ºå·¥å…·è°ƒç”¨
    """
    print(f"- {tool_name}({','.join(f'{k}={v}' for k, v in args.items())})")
    return args


def tools_after_hook(result: Any, tool_name: str, session) -> Any:
    """
    æ˜¾ç¤ºå·¥å…·è°ƒç”¨ç»“æœ
    """
    print(f"â¿ {result}")
    return result

def demo_default_runner():
    """æ¼”ç¤ºé»˜è®¤ Runner"""
    print("\n=== é»˜è®¤ Runner ç¤ºä¾‹ ===")
    
    # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿçš„é…ç½®ï¼‰
    from openai import OpenAI
    openai_raw_client = OpenAI(
        base_url="http://192.168.1.16:11434/v1",
        api_key="EMPTY"
    )
    client = OpenAIClient(openai_raw_client)
    
    # åˆ›å»ºä¼šè¯ï¼ˆæµå¼ï¼‰
    session = LLMSession(
        client=client,
        tools=[get_weather, calculate],
        config=AgentConfig(model="gpt-oss:20b", temperature=0.1),
        stream=True,
        system_prompt="ä½ æ˜¯ä¸€ä¸ªhelpfulçš„AIåŠ©æ‰‹ã€‚",
        before_tool_calling=[tools_before_hook],
        after_tool_calling=[tools_after_hook]
    )
    
    # ä½¿ç”¨é»˜è®¤Runner
    runner = DefaultRunner(session)
    runner.run("åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿç„¶åå¸®æˆ‘è®¡ç®— 15 * 23")
        


def demo_non_streaming():
    """æ¼”ç¤ºéæµå¼ Runner"""
    print("\n=== éæµå¼ Runner ç¤ºä¾‹ ===")
    
    try:
        from openai import OpenAI
        openai_raw_client = OpenAI(
            base_url="http://192.168.1.16:11434/v1",
            api_key="EMPTY"
        )
        client = OpenAIClient(openai_raw_client)
        
        # åˆ›å»ºéæµå¼ä¼šè¯
        session = LLMSession(
            client=client,
            tools=[get_weather],
            config=AgentConfig(model="gpt-oss:20b"),
            stream=False  # å…³é”®ï¼šè®¾ä¸ºéæµå¼
        )
        
        # ä»»ä½•Runneréƒ½æ”¯æŒéæµå¼
        runner = DefaultRunner(session)
        result = runner.run("åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        
    except Exception as e:
        print(f"æ¼”ç¤ºå¤±è´¥: {e}")


if __name__ == "__main__":
    print("Runner ç±»ä½¿ç”¨ç¤ºä¾‹")
    print("æ³¨æ„: éœ€è¦é…ç½®æ­£ç¡®çš„LLMæœåŠ¡ç«¯ç‚¹æ‰èƒ½è¿è¡Œ")
    
    # è¿è¡Œå„ç§æ¼”ç¤º
    demo_default_runner()
    demo_non_streaming()
    
    print("\næ¼”ç¤ºå®Œæˆ! ğŸ‰")