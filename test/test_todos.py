#!/usr/bin/env python3
"""
æµ‹è¯•ä½¿ç”¨Ollama qwen2.5vl:7bæ¨¡å‹åˆ›å»ºtodosåˆ—è¡¨çš„ç¤ºä¾‹

è¿è¡Œå‰è¯·ç¡®ä¿ï¼š
1. å·²å®‰è£…Ollamaï¼šcurl -fsSL https://ollama.com/install.sh | sh
2. å·²ä¸‹è½½qwen2.5vl:7bæ¨¡å‹ï¼šollama pull qwen2.5vl:7b
3. OllamaæœåŠ¡æ­£åœ¨è¿è¡Œï¼šollama serve
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from hq_agent_sdk import LLMSession, OpenAIClient, AgentConfig
from hq_agent_sdk import create_todos, update_todos, query_todos
from openai import OpenAI

def main():
    """ä½¿ç”¨ OpenAI gpt-oss:20b æ¨¡å‹æµ‹è¯•todosåŠŸèƒ½"""
    
    print("ğŸš€ å¯åŠ¨ OpenAI gpt-oss:20b æ¨¡å‹æµ‹è¯•todosåŠŸèƒ½...")
    
    # åˆ›å»ºOllamaå®¢æˆ·ç«¯
    client = OpenAIClient(
         OpenAI(
            base_url="http://192.168.1.16:11434/v1",
            api_key="EMPTY"
        )
    )
    
    # é…ç½®å‚æ•°
    config = AgentConfig(
        model="gpt-oss:20b",
        temperature=0.7,
        max_iterations=5
    )
    
    # åˆ›å»ºLLMä¼šè¯ï¼ŒåŒ…å«todoså·¥å…·
    session = LLMSession(
        client=client,
        config=config,
        tools=[create_todos, update_todos, query_todos],
        stream=False,
        system_prompt="""ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®ç®¡ç†åŠ©æ‰‹ã€‚ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·åˆ›å»ºå’Œç®¡ç†ä»»åŠ¡åˆ—è¡¨ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚åˆç†ä½¿ç”¨è¿™äº›å·¥å…·ã€‚"""
    )
    
    print(f"âœ… æˆåŠŸåˆ›å»ºä¼šè¯ï¼ŒSession ID: {session.session_id}")
    
    # æµ‹è¯•åœºæ™¯1ï¼šè®©AIåˆ›å»ºä¸€ä¸ªè½¯ä»¶å¼€å‘é¡¹ç›®çš„todosåˆ—è¡¨
    print("\n" + "="*60)
    print("ğŸ“‹ æµ‹è¯•åœºæ™¯1: åˆ›å»ºè½¯ä»¶å¼€å‘é¡¹ç›®ä»»åŠ¡åˆ—è¡¨")
    print("="*60)
    
    user_message = """è¯·å¸®æˆ‘åˆ›å»ºä¸€ä¸ªWebåº”ç”¨å¼€å‘é¡¹ç›®çš„ä»»åŠ¡åˆ—è¡¨ï¼ŒåŒ…æ‹¬ï¼š
1. éœ€æ±‚åˆ†æå’Œè®¾è®¡
2. å‰ç«¯å¼€å‘
3. åç«¯APIå¼€å‘  
4. æ•°æ®åº“è®¾è®¡
5. æµ‹è¯•å’Œéƒ¨ç½²
6. æ–‡æ¡£ç¼–å†™"""
    
    print(f"ç”¨æˆ·: {user_message}")
    print("\nğŸ¤– AIå›å¤:")
    
    response = session.call(user_message)
    print(response.message.content)
    
    # æµ‹è¯•åœºæ™¯2ï¼šæŸ¥è¯¢åˆ›å»ºçš„ä»»åŠ¡åˆ—è¡¨
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•åœºæ™¯2: æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡")
    print("="*60)
    
    query_message = "è¯·æ˜¾ç¤ºæ‰€æœ‰ä»»åŠ¡çš„å½“å‰çŠ¶æ€"
    print(f"ç”¨æˆ·: {query_message}")
    print("\nğŸ¤– AIå›å¤:")
    
    response = session.call(query_message)
    print(response.message.content)
    
    # æµ‹è¯•åœºæ™¯3ï¼šæ›´æ–°ä»»åŠ¡çŠ¶æ€
    print("\n" + "="*60)
    print("â³ æµ‹è¯•åœºæ™¯3: æ›´æ–°ä»»åŠ¡çŠ¶æ€")
    print("="*60)
    
    update_message = "è¯·å°†ç¬¬ä¸€ä¸ªä»»åŠ¡æ ‡è®°ä¸ºè¿›è¡Œä¸­ï¼Œç¬¬äºŒä¸ªä»»åŠ¡æ ‡è®°ä¸ºå·²å®Œæˆ"
    print(f"ç”¨æˆ·: {update_message}")
    print("\nğŸ¤– AIå›å¤:")
    
    response = session.call(update_message)
    print(response.message.content)


    # æµ‹è¯•åœºæ™¯2ï¼šæŸ¥è¯¢åˆ›å»ºçš„ä»»åŠ¡åˆ—è¡¨
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•åœºæ™¯3.1: æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡")
    print("="*60)
    
    query_message = "è¯·æ˜¾ç¤ºæ‰€æœ‰ä»»åŠ¡çš„å½“å‰çŠ¶æ€"
    print(f"ç”¨æˆ·: {query_message}")
    print("\nğŸ¤– AIå›å¤:")
    
    response = session.call(query_message)
    print(response.message.content)
    
    # æµ‹è¯•åœºæ™¯4ï¼šæŸ¥è¯¢ç‰¹å®šçŠ¶æ€çš„ä»»åŠ¡
    print("\n" + "="*60)
    print("ğŸ¯ æµ‹è¯•åœºæ™¯4: æŸ¥è¯¢è¿›è¡Œä¸­çš„ä»»åŠ¡")
    print("="*60)
    
    filter_message = "è¯·åªæ˜¾ç¤ºçŠ¶æ€ä¸º'è¿›è¡Œä¸­'çš„ä»»åŠ¡"
    print(f"ç”¨æˆ·: {filter_message}")
    print("\nğŸ¤– AIå›å¤:")
    
    response = session.call(filter_message)
    print(response.message.content)
    
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“Š ä¼šè¯ç»Ÿè®¡:")
    print(f"  - Session ID: {session.session_id}")
    print(f"  - æ¶ˆæ¯æ•°é‡: {len(session.messages)}")
    print(f"  - æ¨¡å‹: {config.model}")
        

if __name__ == "__main__":
    main()